{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab09.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Lab\n",
    "\n",
    "### Adapted from Lab 9 in Fall 2019\n",
    "\n",
    "**Note for NWDSE:** This lab uses our old (Spring 2020 and prior) grading platform, `okpy`. Summer 2020 and onwards will use `otter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this lab, we'll review some of the details of how linear regression works as described in lectures 14 and 15. \n",
    "\n",
    "We will also show how to do linear regression using various real world tools including `seaborn`, `scipy.optimize`, and `scikit-learn`. In real world data science work, you are far more likely to use something similar to the first (`seaborn`) and fourth (`scikit-learn`) approaches, but it's important to know how to use the second (formulaic) and third (`scipy.optimize`) approaches so that you understand what's really going on.\n",
    "\n",
    "**This assignment should be completed and submitted before 11:59 PM on Monday, Oct 21, 2019.**\n",
    "\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk to others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_List collaborators here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the tips dataset that we also explored in Lab 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab 3, we fit a **constant** model to this dataset. In other words, given the set of tips `tips['tip']`, we tried to find a summary statistic $c$ that best represented our set of tips. To find the value of $c$, we minimized the following empirical risk:\n",
    "\n",
    "$$L(c, \\mathcal{D}) = \\sum_{i = 1}^n L(x_i, c)$$\n",
    "\n",
    "Here, $\\mathcal{D} = \\{x_1, x_2, ..., x_n \\}$ refers to our set of `tips` values.\n",
    "\n",
    "We looked at two different loss functions:\n",
    "\n",
    "- $L_2$: $L_2(x_i, c) = (x_i - c)^2$\n",
    "\n",
    "- $L_1$: $L_1(x_i, c) = \\left| x_i - c \\right|$\n",
    "\n",
    "<br>\n",
    "\n",
    "By contrast, in this lab, we're interested in studying the **relationship between two variables**. Specifically, we're interested in the relationship between the `total_bill` column and `tip` column. Our goal will be to predict tip ($y$) from total_bill ($x$), i.e., we want to find values of $a$ and $b$ so that given $x$, predict $y$ as\n",
    "$$\\boxed{a + bx}$$\n",
    "We will now explore different ways to obtain the optimal values of $a, b$, called $\\hat{a}, \\hat{b}$, where $\\hat{y} = \\hat{a} + \\hat{b}x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's run `sns.lmplot`, which will both provide a scatterplot of `tip` vs `total_bill` and also display the least-squares line of best fit. This line of best fit is what we will look to determine empirically in three different ways: manually using the formula from lecture, `scipy.optimize`, and `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data = tips, x = \"total_bill\", y = \"tip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 – Manual Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Lecture 14](http://www.ds100.org/fa19/resources/assets/lectures/lec14/14-SimpleLinearRegressionPDF.pdf), we derived the following expression for the line of best fit.\n",
    "\n",
    "$$\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$$\n",
    "\n",
    "where $\\bar{x}$, $\\bar{y}$, $SD(x)$, $SD(y)$ correspond to the means and standard deviations of $x$ and $y$, respectively, and $r$ is the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a\n",
    "\n",
    "Assign `xbar`, `ybar`, `stdx`, `stdy`, and `r`, such that they align with our dataset.\n",
    "\n",
    "- Hint: Remember, in our case, `y` is `tip`, and `x` is `total_bill`.\n",
    "- Hint: You may find `np.corrcoef` handy in computing `r`. Note that the output of `np.corrcoef` is a matrix, not a number, so you'll need to collect the correlation coefficient by indexing into the returned array. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = ... # YOUR CODE HERE\n",
    "ybar = ... # YOUR CODE HERE\n",
    "stdx = ... # YOUR CODE HERE\n",
    "stdy = ... # YOUR CODE HERE\n",
    "r = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, set `b_hat` and `a_hat` correctly, in terms of the variables you defined above. \n",
    "\n",
    "- Hint: Try and match the slope and intercept in $\\hat{y_i} = \\hat{a} + \\hat{b}x_i$ to the slope and intercept in $\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$.\n",
    "\n",
    "- Hint: You may want to define `a_hat` in terms of `b_hat`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat = ... # YOUR CODE HERE\n",
    "a_hat = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "Now, use `a_hat` and `b_hat` to predict the tip for a total bill amount of \\$20. Store your result in `predicted_20`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_20 = ... # YOUR CODE HERE\n",
    "predicted_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1d\n",
    "Assign `regression` to be a `pd.Series` of predicted $y$ values (i.e., predicted `\"tip\"` values) for the observed total bills (`tips[\"total_bill\"]`). You will need to use `a_hat`, `b_hat`, and `tips[\"total_bill\"]`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = a_hat + b_hat * tips[\"total_bill\"] # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you defined `regression` correctly, the following cell will generate a scatter plot of `tip` vs. `total_bill`, along with the line of best fit you just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tips[\"total_bill\"], tips[\"tip\"]);\n",
    "plt.plot(tips[\"total_bill\"], regression, color = 'r');\n",
    "plt.xlabel('total_bill');\n",
    "plt.ylabel('tip');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $r$, the correlation coefficient between `tips` and `total_bill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**In the cell below**, comment on the value of $r$, and what it means in the context of the above scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 – Using Scipy Minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.minimize` is a powerful method that can determine the optimal value of a variety of different functions. In practice, it is used to minimize functions that have no (or difficult to obtain) analytical solutions (it is a **numerical method**).\n",
    "\n",
    "It is overkill for our simple example, but nonetheless, we will show you how to use it, as it will become useful in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Firstly, fill out the definition of `l2_tip_loss` so that it computes the empirical risk for a given choice of `a` and `b`. That is, it computes\n",
    "\n",
    "$$\\frac{1}{n} \\sum_{i = 1}^n(y_i - (a - b x_i))^2$$\n",
    "\n",
    "where, again, $x$ and $y$ refer to `\"total_bill\"` and `\"tip\"`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_tip_loss(a, b):\n",
    "    \"\"\"Returns average l2 loss between regression line for intercept a \n",
    "       and slope b\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out different `a` and `b` values. Observe that if you pick values close to the ones from the earlier part of this lab then the loss is lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_tip_loss(0.9, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minimize` function we saw in Lab 3 can also minimize functions of multiple variables. There's one quirk, however, which is that the function has to accept its parameters as a single list.\n",
    "\n",
    "For example, consider the multivariate $f(u, v) = u^2 - 2 u v - 3 v + 2 v^2$. It turns out this function's minimum is at $(1.5, 1.5)$. To minimize this function, we create `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta):\n",
    "    u = theta[0]\n",
    "    v = theta[1]\n",
    "    return u**2 - 2 * u * v - 3 * v + 2 * v**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(f, x0 = [0.0, 0.0]) \n",
    "\n",
    "# As an aside: x0 is the \"initial guess\" for the optimal theta. minimize works iteratively.\n",
    "# We will study an iterative algorithm for function minimization in the coming weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Define `l2_tip_loss_list` which is exactly like `l2_tip_loss` except that it takes in a single list of 2 variables rather than two separate variables. For example `l2_tip_loss_list([2, 3])` should return the same value as `l2_tip_loss(2, 3)`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_tip_loss_list(theta):\n",
    "    \"\"\"Returns average l2 loss between regression line for intercept a \n",
    "       and slope b\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2c\n",
    "\n",
    "Now, set `minimized` to the result of calling `minimize` to optimize this loss function.\n",
    "\n",
    "- Hint: Make sure to set `x0`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of your call to `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will print out the values of `a_hat` and `b_hat` computed from both methods (\"manual\" refers to the technique in Question 1). If you've done everything correctly, these should be very close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_hat_scipy: ', minimized['x'][0])\n",
    "print('a_hat_manual: ', a_hat)\n",
    "print('\\n')\n",
    "print('b_hat_scipy: ', minimized['x'][1])\n",
    "print('b_hat_manual: ', b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason these don't match past the first 5 decimal places is due to the fact that `scipy.minimize` is a numerical method, meaning it approximates the optimal value using some sort of non-algebraic procedure. For our purposes, though, these values are essentially the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 – Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another way to fit a linear regression model is to use scikit learn, an industry standard package for machine learning applications. \n",
    "\n",
    "To do so, we first create a `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `model` is like a \"blank slate\" for a linear model. Now, we need to tell `model` to \"fit\" itself to the data. Essentially, this is doing exactly what you did in the previous part of this lab (creating a loss function and finding the parameters that minimize that loss).\n",
    "\n",
    "<i>Note: `X` needs to be a matrix (or DataFrame), as opposed to a single array (or Series). This is because `sklearn.linear_model` is robust enough to be used for multiple regression, which we will look at in Question 4.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X = tips[['total_bill']], y= tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model exists, we can look at the a_hat and b_hat values it found, which are given in the attributes `intercept` and `coef`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `scikit-learn` linear regression model to make predictions, you can use the `model.predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code tells us that `model` predicts a tip of \\$3.02 given a total bill amount of \\$20. This is the same as doing `a_hat + b_hat * 20` as in Question 1c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Create a linear regression plot using `model.predict`. It should look very similar (if not the same) as your plot from Question 1d.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 – Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous parts we showed how to establish relationships between one independent explanatory variable and one response variable. However, with real-world problems you will often want to use **multiple features** to model and predict a response variable. To do so, we will use multiple linear regression, as discussed in [Lecture 15](http://www.ds100.org/fa19/resources/assets/lectures/lec15/15-MultipleRegressionGeometric.pdf). Multiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to the observed data. Formally, the model for multiple linear regression, given $p$ features is:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + … + \\beta_p x_p $$\n",
    "\n",
    "Please note that we have been using the terms **features**, **independent variables**, and **explanatory variables** interchangeably. Usually “features” are used in the context of machine learning when you are trying to make predictions. “Independent variables” and “explanatory variables” are mainly found in statistics, econometrics and other related fields which focus on understanding the relationship between a set of variables.  \n",
    "\n",
    "\n",
    "For example, consider the plot below which shows fuel efficiency vs. engine power for several models of automobile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we load the fuel dataset, and drop any rows that have missing data\n",
    "vehicle_data = sns.load_dataset('mpg').dropna()\n",
    "vehicle_data = vehicle_data.sort_values('horsepower', ascending=True)\n",
    "vehicle_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `horsepower` alone to predict `mpg`, we get not-so-great results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='horsepower', y='mpg', data=vehicle_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we discussed including functions of existing features as new features. For example, the line below adds a column which contains the square of the horsepower for each car in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data['hp^2'] = vehicle_data['horsepower'] ** 2\n",
    "vehicle_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "Using scikit learn's `LinearRegression`, create and fit a model that tries to predict `mpg` from `horsepower` AND `hp^2`. Name your model `model_multiple`.\n",
    "\n",
    "- Hint: We do something very similar in Question 3.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple = LinearRegression()\n",
    "... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can see the coefficients and intercept. Note, there are now two elements in `model_multiple.coef_`, since there are two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b\n",
    "\n",
    "Using the above values, in LaTeX, write out the function that the model is using to predict `mpg` from `horsepower` and `hp^2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the prediction of our model. It's much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "predicted_mpg = model_multiple.predict(vehicle_data[['horsepower', 'hp^2']])\n",
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data)\n",
    "plt.plot(vehicle_data['horsepower'],  predicted_mpg, color = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4c\n",
    "\n",
    "In the cell below, explain why we use the term \"linear\" to describe the model above, even though it incorporates horsepower squared as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see exactly how much better our new model is, we can compare the Multiple $R^2$ from these two fits.  As described in lecture 15,\n",
    "\n",
    "$$R^2 = \\frac{\\text{Explained SS}}{\\text{Total SS}}$$\n",
    "\n",
    "Recall, the \"explained\" sum of squares (SS) is $\\sum(\\hat{y}_i - \\bar{y})^2$ and the \"total\" sum of squares is $\\sum(y_i -  \\bar{y})^2$, so we can\n",
    "compute $R^2$ from the ratio of variances:\n",
    "\n",
    "$$R^2 =  \\frac{\\textrm{Var}( \\hat{y} \\:\\:)}  {\\textrm{Var}({y})}$$\n",
    "\n",
    "Unlike $r$, the correlation coefficient we looked at in Question 1, $R^2$  can be used\n",
    "in the multiple regression setting.  In simple regression, $r^{2}$ and Multiple $R^{2}$ are\n",
    "the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mpg_horsepower_only = (\n",
    "    LinearRegression()\n",
    "    .fit(X = vehicle_data[['horsepower']], y = vehicle_data['mpg'])\n",
    "    .predict(vehicle_data[['horsepower']])\n",
    ")\n",
    "\n",
    "r2_horsepower_only = np.var(predicted_mpg_horsepower_only) / np.var(vehicle_data['mpg'])\n",
    "r2_both = np.var(predicted_mpg) / np.var(vehicle_data['mpg'])\n",
    "\n",
    "print('Multiple R^2 using only horsepower: ', r2_horsepower_only)\n",
    "print('Multiple R^2 using both horsepower and horsepower squared: ', r2_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By introducing `hp^2` as a feature, our multiple $R^2$ value increased. What does this mean about the strength of our refined model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4d\n",
    "\n",
    "Let's take this one step further, and introduce a few more features.\n",
    "\n",
    "Again, using scikit learn's `LinearRegression`, create and fit a model that tries to predict `mpg` using each of the following as features:\n",
    "- `horsepower`\n",
    "- `hp^2`\n",
    "- `model_year`\n",
    "- `acceleration`\n",
    "\n",
    "Call your model `model_many`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns = ... # YOUR CODE HERE\n",
    "model_many = LinearRegression()\n",
    "model_many.fit(X = vehicle_data[desired_columns], y= vehicle_data['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the prediction of our more sophisticated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_mpg_many = model_many.predict(vehicle_data[['horsepower', 'hp^2', 'model_year', 'acceleration']])\n",
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data)\n",
    "plt.plot(vehicle_data['horsepower'],  predicted_mpg_many, color = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about what you see in the above plot. Why is the shape of our prediction curve so jagged? Do you think this is a good model to predict the `mpg` of some car we don't already have information on?\n",
    "\n",
    "This idea – the **bias-variance tradeoff** – is an idea we will explore in the coming weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4e\n",
    "\n",
    "Lastly, set `r2_many` to be the multiple $R^2$ coefficient obtained by using `model_many`.\n",
    "\n",
    "- Hint: This is very similar to what we did right before Question 4d. Use `predicted_mpg_many`.\n",
    "- Note: The above plotting cell needs to have been run in order for this to work.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4e\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_many = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4e\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multiple R^2 using only horsepower: ', r2_horsepower_only)\n",
    "print('Multiple R^2 using both horsepower and horsepower squared: ', r2_both)\n",
    "print('Multiple R^2 using horsepower, horsepower squared, model year, and acceleration: ', r2_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything was done correctly, the multiple $R^2$ of our latest model should be substantially higher than that of the previous two models. Think about why this is the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "# ok.submit() --> this line won't work now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
